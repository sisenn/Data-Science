{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da6d31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167622ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBu bölümde yoğun biçimde kullandığımız iris verisini bu kez PCA verilerinin oluşturulması amacıyla kullanacağız. \\nAmacımız iris verisinin 4 özniteliğinin sayısını azaltarak 2 özniteliğe dönüştürülmesini sağlamaktır.\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bu bölümde yoğun biçimde kullandığımız iris verisini bu kez PCA verilerinin oluşturulması amacıyla kullanacağız. \n",
    "Amacımız iris verisinin 4 özniteliğinin sayısını azaltarak 2 özniteliğe dönüştürülmesini sağlamaktır.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3920dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
      "       'petal width (cm)'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z-score normalizasyonu yöntemini yukarıda yer verilen iris veri kümesine uygulamak amacındayız. \n",
    "#Veri kümesi yine veri deposundan doğrudan Python oturumuna yüklenir.\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "data = pd.DataFrame(data = iris.data,columns=iris.feature_names)\n",
    "\n",
    "names = data.columns\n",
    "\n",
    "\n",
    "print(names)\n",
    "print(\"\\n\")\n",
    "print(data.head())\n",
    "#verinin satır ve sütun uzunluğuna bakıyoruz.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ed9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boyut azaltma işlemine başlamadan önce, gerekli karşılaştırmaları yapmak üzere içeriği görüntülenir. \n",
    "#Burada yer alan ilk 4 öznitelik yerine PCA ile dönüştürülmüş 2 öznitelikli yeni bir veri seti elde edilecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00c42f89",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Sınıf özniteliği ayrılır\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# PCA yöntemini uygulayabilmek için ilgili verinin normalize edilmesi beklenir.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Normalleştirme işlemi\u001b[39;00m\n\u001b[1;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit_transform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1652\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1652\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:940\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    945\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1554\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 1554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1556\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1647\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Öncelikle PCA uygulanacak öznitelikler seçilir. Biz mevcut 4 öznitelik için uygulanmasını istiyoruz. X veri çerçevesi seçilen bu öznitelik değerlerini içerir.\n",
    "# Öznitelikler seçilir\n",
    "X = data.iloc[:, 0:4].values\n",
    "\n",
    "# Sınıf özniteliği ayrılır\n",
    "y = data.iloc[:, 4].values\n",
    "\n",
    "# PCA yöntemini uygulayabilmek için ilgili verinin normalize edilmesi beklenir.\n",
    "# Normalleştirme işlemi\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Gerekli ön işlemler yapıldıktan sonra sıra PCA işlemine gelir. Bu amaçla aşağıdaki işlemler gerçekleştirilir. Bu işlemler sonucunda dört öznitelikten oluşan veri kümesi iki özniteliğe dönüşür.\n",
    "# PCA işleminin yapılması\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "PCA_bilesenleri = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8233adeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# PCA verisi DataFrame'e dönüştürülür\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m PCA_veri \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mPCA_bilesenleri, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA 2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(PCA_veri\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# PCA verisi DataFrame'e dönüştürülür\n",
    "\n",
    "PCA_veri = pd.DataFrame(data=PCA_bilesenleri, columns=['PCA 1', 'PCA 2'])\n",
    "\n",
    "print(PCA_veri.head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Bu veri kümesini sınıf özniteliği olan y vektörü ile birleştirerek analizler için hazır bir \n",
    "#veri kümesi elde edilir.\n",
    "\n",
    "y = pd.DataFrame(y, columns=[\"Species\"])\n",
    "sonuc_veri = pd.concat([PCA_veri, y], axis=1)\n",
    "\n",
    "print(sonuc_veri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba8d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c648480-4c20-4407-9aaa-8aecfd017bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
